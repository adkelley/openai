/// Allow the API to select a function 'horoscope' to return a user's horoscope
/// TODO: Should some of this data wrangling go into the responses.gleam code?
import envoy
import gleam/io
import gleam/json.{type Json}
import gleam/list
import gleam/option.{Some}

import openai/error.{type OpenaiError}
import openai/responses
import openai/types/responses/create_response as cr

// Auto, ContentText, FunctionCallOutput, FunctionCalling, InputList,
// InputListItemMessage, OutputFunctionCall, OutputReasoning,
// OutputReasoningContent, OutputReasoningSummary, RoleContent,
import openai/types/responses/response.{type Response}
import openai/types/shared

/// Requires `OPENAI_API_KEY` to be set in the environment.
pub fn main() -> Result(Response, OpenaiError) {
  let assert Ok(api_key) = envoy.get("OPENAI_API_KEY")

  // 1. Define list of callable tools for the model
  let parameters_encoder = fn() -> Json {
    json.object([
      #("type", json.string("object")),
      #(
        "properties",
        json.object([
          #(
            "sign",
            json.object([
              #("type", json.string("string")),
              #(
                "description",
                json.string("An astrological sign like Taurus or Aquarius"),
              ),
            ]),
          ),
        ]),
      ),
      #("required", json.array(["sign"], of: json.string)),
      #("additionalProperties", json.bool(False)),
    ])
  }

  let horoscope_tool =
    cr.FunctionCalling(
      name: "get_horoscope",
      description: "Get today's horoscope for an astrological sign",
      parameters: parameters_encoder(),
      strict: True,
    )

  let get_horoscope = fn(_arguments: String) -> String {
    json.object([
      #("sign", json.string("Cancer")),
      #(
        "horoscope",
        json.string("Next Tuesday you will befriend a  baby otter"),
      ),
    ])
    |> json.to_string()
  }

  // Create a running input list we will add over time
  let content_text = "What is my horoscope?  I am a Cancer"
  let hop1 = [
    cr.InputListItemMessage(cr.RoleContent(
      role: "user",
      content: cr.ContentText(content_text),
    )),
  ]
  io.println("\nPrompt: " <> content_text)

  let config =
    responses.default_request()
    |> responses.model(shared.GPT51)
    |> responses.input(cr.ResponseInput(hop1))
    |> responses.tool_choice(cr.ToolChoiceOptions(cr.Auto))
    // Define the list of callable tools for the model
    |> responses.tools(Some([]), horoscope_tool)

  // 2. Prompt the model with tools defined
  let assert Ok(response) = responses.create(api_key, config)
  // echo response.output

  // TODO Should this merging of input and output go into
  // `responses.gleam`
  // Importantly [hop1, reasoning, fn_call1, fn_call2, out1, out2]

  let hop2 =
    list.fold(response.output, hop1, fn(acc, item) {
      case item {
        response.OutputReasoning(id:, summary:, content:) -> {
          list.append(acc, [
            cr.InputListItemMessage(cr.OutputReasoning(
              id:,
              summary: list.fold(summary, [], fn(acc, text_item) {
                case text_item {
                  response.OutputReasoningSummary(text:) ->
                    list.prepend(acc, cr.OutputReasoningSummary(text))
                }
              })
                |> list.reverse,
              content: list.fold(content, [], fn(acc, text_item) {
                case text_item {
                  response.OutputReasoningContent(text:) ->
                    list.prepend(acc, cr.OutputReasoningContent(text))
                }
              })
                |> list.reverse,
            )),
          ])
        }
        response.OutputFunctionCall(status:, id:, call_id:, name:, arguments:) -> {
          list.append(acc, [
            cr.InputListItemMessage(cr.OutputFunctionCall(
              status,
              id,
              call_id,
              name,
              arguments,
            )),
          ])
          |> fn(acc_) {
            case name {
              "get_horoscope" -> {
                let horoscope = get_horoscope(arguments)
                list.append(acc_, [
                  cr.InputListItemMessage(cr.FunctionCallOutput(
                    call_id:,
                    output: json.string(horoscope),
                  )),
                ])
              }
              _ -> panic as "unrecognized function call"
            }
          }
        }
        _ -> acc
      }
    })

  let config =
    responses.default_request()
    |> responses.model(shared.GPT51)
    |> responses.instructions(Some(
      "Respond only with a horoscope generated by a tool.",
    ))
    |> responses.input(cr.ResponseInput(hop2))
    // Define the list of callable tools for the model
    |> responses.tools(Some([]), horoscope_tool)

  let assert Ok(response) = responses.create(api_key, config)
  echo response.output
  Ok(response)
}
