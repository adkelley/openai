/// Issues a Responses API call configured to delegate web search to an MCP server.
import envoy
import gleam/dynamic/decode
import gleam/io
import gleam/json.{type Json}
import gleam/list
import gleam/option.{Some}

import openai/error.{type OpenaiError}
import openai/responses
import openai/responses/types/request.{
  Auto, ContentInputText, FunctionCallOutput, FunctionCalling, InputList,
  InputListItemMessage, RoleContent,
}
import openai/responses/types/response.{type Response}
import openai/types as shared

/// Requires `OPENAI_API_KEY` to be set in the environment.
pub fn main() -> Result(Response, OpenaiError) {
  let assert Ok(api_key) = envoy.get("OPENAI_API_KEY")

  // 1. Define list of callable tools for the model
  let parameters_encoder = fn() -> Json {
    json.object([
      #("type", json.string("object")),
      #(
        "properties",
        json.object([
          #(
            "sign",
            json.object([
              #("type", json.string("string")),
              #(
                "description",
                json.string("An astrological sign like Taurus or Aquarius"),
              ),
            ]),
          ),
        ]),
      ),
      #("required", json.array(["sign"], of: json.string)),
      #("additionalProperties", json.bool(False)),
    ])
  }

  let horoscope_tool =
    FunctionCalling(
      name: "get_horoscope",
      description: "Get today's horoscope for an astrological sign",
      parameters: parameters_encoder(),
      strict: True,
    )

  let get_horoscope = fn(_arguments: String) -> String {
    "Cancer" <> " Next Tuesday you will befriend a baby otter."
  }

  // Create a running input list we will add over time
  let content_input_text = "What is my horoscope?  I am a Cancer"
  let input =
    InputList([
      InputListItemMessage(RoleContent(
        role: "user",
        content: ContentInputText(content_input_text),
      )),
    ])
  io.println("\nPrompt: " <> content_input_text)

  let config =
    responses.default_request()
    |> responses.model(shared.GPT41)
    |> responses.input(input)
    |> responses.function_tool_choice(Auto)
    // Define the list of callable tools for the model
    |> responses.tools(Some([]), horoscope_tool)

  // 2. Prompt the model with tools defined
  let assert Ok(response) = responses.create(api_key, config)
  echo response.output

  let InputList(input_) = input
  let input =
    list.fold(response.output, input_, fn(acc, item) {
      echo acc
      case item {
        response.OutputFunctionCall(_, _, call_id:, name:, arguments:) ->
          case name == "get_horoscope" {
            True -> {
              echo arguments
              let horoscope = get_horoscope(arguments)
              echo horoscope
              list.prepend(
                acc,
                InputListItemMessage(FunctionCallOutput(
                  call_id:,
                  output: json.string(horoscope),
                )),
              )
            }
            False -> acc
          }

        // response.OutputReasoning(id:, summary:, content:) ->
        //       list.prepend(
        //         acc,
        //         InputListItemMessage(FunctionCallOutput(
        //           call_id:,
        //           output: json.string(horoscope),
        //         )),
        //       )
        //     }
        //     False -> acc
        //   }
        _ -> acc
      }
    })
    |> InputList()

  echo "input"
  echo input
  let config =
    responses.default_request()
    |> responses.model(shared.GPT41)
    |> responses.instructions(Some(
      "Respond only with a horoscope generated by a tool.",
    ))
    |> responses.input(input)
    // Define the list of callable tools for the model
    |> responses.tools(Some([]), horoscope_tool)

  let assert Ok(response) = responses.create(api_key, config)
  echo response.output

  Ok(response)
}
