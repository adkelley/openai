import gleam/dict.{type Dict}
import gleam/dynamic
import gleam/dynamic/decode.{type Decoder}
import gleam/option.{type Option}

pub type Response {
  Response(
    /// Whether to run the model response in the background.
    background: Bool,
    /// Unique identifier for this Response.
    id: String,
    /// The object type of this resource - always set to response.
    object: String,
    /// Unix timestamp (in seconds) of when this Response was created.
    created_at: Int,
    // /// The status of the response generation. One of completed, failed, in_progress, cancelled, queued, or incomplete.
    status: String,
    /// ???
    billing: Billing,
    // An error object returned when the model fails to generate a Response.
    error: Option(Error),
    /// Details about why the response is incomplete.
    incomplete_details: Option(IncompleteDetails),
    /// A system (or developer) message inserted into the model's context. When using along with previous_response_id, the
    /// instructions from a previous response will not be carried over to the next response. This makes it simple to swap out
    /// system (or developer) messages in new responses.
    instructions: Option(Instructions),
    /// An upper bound for the number of tokens that can be generated for a response, including visible output
    /// tokens and reasoning tokens.
    max_output_tokens: Option(Int),
    /// The maximum number of total calls to built-in tools that can be processed in a response. This maximum number
    /// applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.
    max_tool_calls: Option(Int),
    /// Model ID used to generate the response, like gpt-4o or o3. OpenAI offers a wide range of models with different
    /// capabilities, performance characteristics, and price points. Refer to the model guide to browse and compare available models.
    model: String,
    /// An array of content items generated by the model. The length and order of items in the output array is dependent on the
    /// model's response. Rather than accessing the first item in the output array and assuming it's an assistant message with
    /// the content generated by the model, you might consider using the output_text property where supported in SDKs.
    output: List(Output),
    /// Whether to allow the model to run tool calls in parallel.
    parallel_tool_calls: Bool,
    /// The unique ID of the previous response to the model. Use this to create multi-turn conversations. Learn more about
    /// conversation state. Cannot be used in conjunction with conversation.
    previous_response_id: Option(String),
    /// Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the user field. Learn more.
    prompt_cache_key: Option(String),
    reasoning: Reasoning,
    /// A stable identifier used to help detect users of your application that may be violating OpenAI's usage policies. The IDs should
    /// be a string that uniquely identifies each user. We recommend hashing their username or email address, in order to avoid sending
    /// us any identifying information. Learn more.
    safety_identifier: Option(String),
    // If set to 'default', then the request will be processed with the standard pricing and performance for the selected model.
    // If set to 'flex' or 'priority', then the request will be processed with the corresponding service tier.
    // When not set, the default behavior is 'auto'.
    /// Specifies the processing type used for serving the request.
    /// If set to 'auto', then the request will be processed with the service tier configured in the Project settings.
    /// Unless otherwise configured, the Project will use 'default'.
    service_tier: String,
    /// ???
    store: Bool,
    /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while
    /// lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.
    temperature: Float,
    /// Configuration options for a text response from the model. Can be plain text or structured JSON data.
    text: Text,
    // TODO support the tool choice object (e.g., Allowed tools)
    // 1. none means the model will not call any tool and instead generates a message.
    // 2. auto means the model can pick between generating a message or calling one or more tools.
    // 3. required means the model must call one or more tools.
    /// How the model should select which tool (or tools) to use when generating a response. See the tools parameter to see
    /// how to specify which tools the model can call.
    tool_choice: String,
    /// How the model should select which tool (or tools) to use when generating a response. See the tools parameter to see how
    /// to specify which tools the model can call.
    tools: List(Tool),
    /// An integer between 0 and 20 specifying the number of most likely tokens to return at each token position,
    /// each with an associated log probability.
    top_logprobs: Int,
    /// An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens
    /// with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
    /// We generally recommend altering this or temperature but not both.
    /// gpt-5 and o-series models only
    top_p: Float,
    /// The truncation strategy to use for the model response.
    /// 1. auto: If the input to this Response exceeds the model's context window size, the model will truncate the response to fit the
    /// context window by dropping items from the beginning of the conversation.
    /// 2. disabled (default): If the input size will exceed the context window size for a model, the request will fail with a 400 error.
    truncation: String,
    /// Represents token usage details including input tokens, output tokens, a breakdown of output tokens, and the total tokens used.
    usage: Usage,
    /// DEPRECATED
    /// This field is being replaced by safety_identifier and prompt_cache_key. Use prompt_cache_key instead to maintain caching
    /// optimizations. A stable identifier for your end-users. Used to boost cache hit rates by better bucketing similar requests
    /// and to help OpenAI detect and prevent abuse. Learn more.
    user: Option(String),
    /// Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the
    /// object in a structured format, and querying for objects via API or the dashboard.
    /// Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.
    metadata: Dict(String, String),
  )
}

pub fn response_decoder() -> decode.Decoder(Response) {
  // TODO better error handling
  use error <- decode.field("error", decode.optional(error_decoder()))
  assert error == option.None
  use object <- decode.field("object", decode.string)
  // object is always equal to response
  assert object == "response"
  use background <- decode.field("background", decode.bool)
  use billing <- decode.field("billing", billing_decoder())
  use created_at <- decode.field("created_at", decode.int)
  use id <- decode.field("id", decode.string)
  use incomplete_details <- decode.field(
    "incomplete_details",
    decode.optional(incomplete_details_decoder()),
  )
  use instructions <- decode.field(
    "instructions",
    decode.optional(instructions_decoder()),
  )
  use max_output_tokens <- decode.field(
    "max_output_tokens",
    decode.optional(decode.int),
  )
  use max_tool_calls <- decode.field(
    "max_tool_calls",
    decode.optional(decode.int),
  )
  use model <- decode.field("model", decode.string)
  use status <- decode.field("status", decode.string)
  use output <- decode.field("output", decode.list(output_decoder()))
  use parallel_tool_calls <- decode.field("parallel_tool_calls", decode.bool)
  use previous_response_id <- decode.field(
    "previous_response_id",
    decode.optional(decode.string),
  )
  use prompt_cache_key <- decode.field(
    "prompt_cache_key",
    decode.optional(decode.string),
  )
  use reasoning <- decode.field("reasoning", reasoning_decoder())
  use safety_identifier <- decode.field(
    "safety_identifier",
    decode.optional(decode.string),
  )
  use service_tier <- decode.field("service_tier", decode.string)
  use store <- decode.field("store", decode.bool)
  use temperature <- decode.field("temperature", decode.float)
  use text <- decode.field("text", text_decoder())
  use tool_choice <- decode.field("tool_choice", decode.string)
  use tools <- decode.field("tools", decode.list(tool_decoder()))
  use top_logprobs <- decode.field("top_logprobs", decode.int)
  use top_p <- decode.field("top_p", decode.float)
  use truncation <- decode.field("truncation", decode.string)
  use usage <- decode.field("usage", usage_decoder())
  use user <- decode.field("user", decode.optional(decode.string))
  use metadata <- decode.field(
    "metadata",
    decode.dict(decode.string, decode.string),
  )

  decode.success(Response(
    background:,
    id:,
    object:,
    created_at:,
    status:,
    billing:,
    error:,
    incomplete_details:,
    instructions:,
    max_output_tokens:,
    max_tool_calls:,
    model:,
    output:,
    parallel_tool_calls:,
    previous_response_id:,
    prompt_cache_key:,
    reasoning:,
    safety_identifier:,
    service_tier:,
    store:,
    temperature:,
    text:,
    tool_choice:,
    tools:,
    top_logprobs:,
    top_p:,
    truncation:,
    usage:,
    user:,
    metadata:,
  ))
}

pub type Billing {
  Billing(payer: String)
}

fn billing_decoder() {
  use payer <- decode.field("payer", decode.string)
  decode.success(Billing(payer:))
}

pub type Error {
  Error(code: String, message: String)
}

fn error_decoder() {
  use code <- decode.field("code", decode.string)
  use message <- decode.field("message", decode.string)
  decode.success(Error(code:, message:))
}

pub type IncompleteDetails {
  IncompleteDetails(
    /// The reason why the response is incomplete.
    reason: String,
  )
}

fn incomplete_details_decoder() {
  use reason <- decode.field("reason", decode.string)
  decode.success(IncompleteDetails(reason:))
}

// TODO: add Input Item List
pub type Instructions {
  /// A text input to the model, equivalent to a text input with the developer role.
  InstructionsText(String)
}

fn instructions_decoder() {
  decode.one_of(decode.string |> decode.map(fn(x) { InstructionsText(x) }), [])
}

// This is the type key
pub type Output {
  OutputMessage(
    content: List(OutputMessageContent),
    id: String,
    role: String,
    status: String,
  )
  OutputWebSearchCall(action: Action, id: String, status: String)
  OutputMcpListTools(
    id: String,
    server_label: String,
    tools: List(OutputMcpListTools),
  )
  OutputReasoning(
    /// The unique identifier of the reasoning content.
    id: String,
    /// Reasoning summary content.
    summary: List(OutputReasoningSummary),
    /// Reasoning text content.
    content: List(OutputReasoningContent),
  )
  OutputMcpCall(
    id: String,
    status: String,
    approval_request_id: Option(String),
    arguments: String,
    error: Option(OutputMcpCallError),
    name: String,
    output: String,
    server_label: String,
  )
  OutputMcpApprovalRequest(
    id: String,
    arguments: String,
    name: String,
    server_label: String,
  )
  OutputFunctionCall(
    status: String,
    id: String,
    call_id: String,
    /// The name of the function to call.
    name: String,
    /// Function specifec Json to parse within the caller app
    arguments: String,
  )
  // type "shell_call"
  OutputShellCall(
    id: String,
    call_id: String,
    action: OutputShellCallAction,
    status: String,
    environment: Option(String),
  )
}

fn output_decoder() {
  use type_ <- decode.field("type", decode.string)
  case type_ {
    "message" -> {
      let output_text_decoder = fn() {
        use text <- decode.field("text", decode.string)
        use annotations <- decode.field(
          "annotations",
          decode.list(annotation_decoder()),
        )
        decode.success(OutputText(text:, annotations:))
      }

      let content_item_decoder = fn() {
        use type_ <- decode.field("type", decode.string)
        case type_ {
          "output_text" -> output_text_decoder()
          _ -> {
            echo type_
            panic
          }
        }
      }
      use id <- decode.field("id", decode.string)
      use status <- decode.field("status", decode.string)
      use role <- decode.field("role", decode.string)
      use content <- decode.field(
        "content",
        decode.list(content_item_decoder()),
      )
      decode.success(OutputMessage(content:, id:, role:, status:))
    }

    "web_search_call" -> {
      let action_decoder = fn() -> Decoder(Action) {
        let search_decoder = fn() {
          use query <- decode.field("query", decode.string)
          use sources <- decode.optional_field(
            "sources",
            Sources(url: "n/a"),
            sources_decoder(),
          )
          decode.success(SearchAction(query:, sources:))
        }
        use type_ <- decode.field("type", decode.string)
        case type_ {
          "search" -> search_decoder()
          _ -> {
            echo "action_decoder paniced"
            panic
          }
        }
      }

      use id <- decode.field("id", decode.string)
      use status <- decode.field("status", decode.string)
      use action <- decode.field("action", action_decoder())
      decode.success(OutputWebSearchCall(id:, action:, status:))
    }

    "mcp_list_tools" -> {
      let tool_item_decoder = fn() -> Decoder(OutputMcpListTools) {
        use description <- decode.field("description", decode.string)
        use name <- decode.field("name", decode.string)
        decode.success(OutputMcpToolItem(description:, name:))
      }
      use id <- decode.field("id", decode.string)
      use server_label <- decode.field("server_label", decode.string)
      use tools <- decode.field("tools", decode.list(tool_item_decoder()))
      decode.success(OutputMcpListTools(id:, server_label:, tools:))
    }
    "reasoning" -> {
      let summary_decoder = fn() -> Decoder(OutputReasoningSummary) {
        use text <- decode.field("text", decode.string)
        decode.success(OutputReasoningSummary(text:))
      }
      let output_reasoning_content_decoder = fn() -> Decoder(
        OutputReasoningContent,
      ) {
        use text <- decode.field("text", decode.string)
        decode.success(OutputReasoningContent(text:))
      }
      use id <- decode.field("id", decode.string)
      use summary <- decode.field("summary", decode.list(summary_decoder()))
      use content <- decode.optional_field(
        "content",
        [],
        decode.list(output_reasoning_content_decoder()),
      )
      decode.success(OutputReasoning(id:, summary:, content:))
    }
    "mcp_call" -> {
      let mcp_call_error_decoder = fn() -> Decoder(OutputMcpCallError) {
        use code <- decode.field("call", decode.int)
        use message <- decode.field("text", decode.string)
        decode.success(OutputMcpCallError(code:, message:))
      }
      use id <- decode.field("id", decode.string)
      use status <- decode.field("status", decode.string)
      use approval_request_id <- decode.field(
        "approval_request_id",
        decode.optional(decode.string),
      )
      use arguments <- decode.field("arguments", decode.string)
      use error <- decode.field(
        "error",
        decode.optional(mcp_call_error_decoder()),
      )
      use name <- decode.field("name", decode.string)
      use output <- decode.field("output", decode.string)
      use server_label <- decode.field("server_label", decode.string)
      decode.success(OutputMcpCall(
        id:,
        status:,
        approval_request_id:,
        arguments:,
        error:,
        name:,
        output:,
        server_label:,
      ))
    }
    "mcp_approval_request" -> {
      use id <- decode.field("id", decode.string)
      use arguments <- decode.field("arguments", decode.string)
      use name <- decode.field("name", decode.string)
      use server_label <- decode.field("server_label", decode.string)
      decode.success(OutputMcpApprovalRequest(
        id:,
        arguments:,
        name:,
        server_label:,
      ))
    }
    "function_call" -> {
      use status <- decode.field("status", decode.string)
      use id <- decode.field("id", decode.string)
      use call_id <- decode.field("call_id", decode.string)
      use name <- decode.field("name", decode.string)
      use arguments <- decode.field("arguments", decode.string)
      decode.success(OutputFunctionCall(
        status:,
        id:,
        call_id:,
        name:,
        arguments:,
      ))
    }
    "shell_call" -> {
      let action_decoder = fn() {
        use commands <- decode.field("commands", decode.list(decode.string))
        use timeout_ms <- decode.field("timeout_ms", decode.int)
        use max_output_length <- decode.field("max_output_length", decode.int)
        decode.success(OutputShellCallAction(
          commands:,
          timeout_ms:,
          max_output_length:,
        ))
      }
      use id <- decode.field("id", decode.string)
      use call_id <- decode.field("call_id", decode.string)
      use action <- decode.field("action", action_decoder())
      use status <- decode.field("status", decode.string)
      use environment <- decode.field(
        "environment",
        decode.optional(decode.string),
      )
      decode.success(OutputShellCall(
        id:,
        call_id:,
        action:,
        status:,
        environment:,
      ))
    }

    _ -> {
      echo "output decoder case not found"
      echo type_
      panic
    }
  }
}

pub type OutputShellCallAction {
  OutputShellCallAction(
    commands: List(String),
    timeout_ms: Int,
    max_output_length: Int,
  )
}

pub type OutputMcpCallError {
  OutputMcpCallError(code: Int, message: String)
}

/// Reasoning text content.
pub type OutputReasoningSummary {
  OutputReasoningSummary(text: String)
}

pub type OutputReasoningContent {
  OutputReasoningContent(text: String)
}

pub type OutputMcpListTools {
  OutputMcpToolItem(
    // TODO How to parse annotations
    // annotations: Option(List(Annotation)),
    description: String,
    // TODO ponder parsing input schema
    // input_schema: InputSchema,
    name: String,
  )
}

pub type OutputMessageContent {
  OutputText(annotations: List(Annotation), text: String)
}

pub type OutputTextContent {
  OutputTextContent(annotations: List(Annotation), text: String)
}

pub type Action {
  SearchAction(
    /// The search query.
    query: String,
    /// The sources used in the search.
    sources: Sources,
  )
  OpenPageAction(
    /// The action type.
    /// The URL opened by the model.
    url: String,
  )
  FindAction(
    /// The pattern or text to search for within the page.
    pattern: String,
    /// The URL opened by the model.
    url: String,
  )
}

// pub fn action_decoder() -> Decoder(Action) {
//   let search_decoder = fn() {
//     use query <- decode.field("query", decode.string)
//     use sources <- decode.optional_field(
//       "sources",
//       Sources(url: "n/a"),
//       sources_decoder(),
//     )
//     decode.success(SearchAction(query:, sources:))
//   }
//   use type_ <- decode.field("type", decode.string)
//   case type_ {
//     "search" -> search_decoder()
//     _ -> {
//       echo "action_decoder paniced"
//       panic
//     }
//   }
// }

pub type Sources {
  Sources(
    /// The URL of the source.
    url: String,
  )
}

pub fn sources_decoder() -> Decoder(Sources) {
  // The type of source. Always url.
  use type_ <- decode.field("type", decode.string)
  // TODO Error or panic?
  assert type_ == "url"
  use url <- decode.field("url", decode.string)
  decode.success(Sources(url:))
}

pub type Annotation {
  /// A citation to a file.
  FileCitation(
    /// The ID of the file.
    file_id: String,
    /// The index of the file in the list of files.
    index: Int,
  )
  /// A citation for a web resource used to generate a model response.
  URLCitation(
    /// The index of the last character of the URL citation in the message.
    end_index: Int,
    /// The index of the first character of the URL citation in the message.
    start_index: Int,
    /// The title of the web resource.
    title: String,
    /// The URL of the web resource.
    url: String,
  )
  /// A path to a file.
  FilePath(
    /// The ID of the file.
    file_id: String,
    /// The index of the file in the list of files.
    index: Int,
  )
  /// A citation for a container file used to generate a model response.
  ContainerFileCitation(
    /// The ID of the container file.
    container_id: String,
    /// The index of the last character of the container file citation in the message.
    end_index: Int,
    /// The ID of the file.
    file_id: String,
    /// The filename of the container file cited.
    filename: String,
    /// The index of the first character of the container file citation in the message.
    start_index: Int,
  )
}

pub fn annotation_decoder() {
  let file_citation_decoder = fn() {
    use _file_citation <- decode.field("type", decode.string)
    use file_id <- decode.field("file_id", decode.string)
    use index <- decode.field("index", decode.int)
    decode.success(FileCitation(file_id:, index:))
  }

  let file_path_decoder = fn() {
    use _file_path <- decode.field("type", decode.string)
    use file_id <- decode.field("file_id", decode.string)
    use index <- decode.field("index", decode.int)
    decode.success(FilePath(file_id:, index:))
  }

  let url_citation_decoder = fn() {
    use _url_citation <- decode.field("type", decode.string)
    use end_index <- decode.field("end_index", decode.int)
    use start_index <- decode.field("start_index", decode.int)
    use title <- decode.field("title", decode.string)
    use url <- decode.field("url", decode.string)
    decode.success(URLCitation(end_index:, start_index:, title:, url:))
  }

  let container_file_citation_decoder = fn() {
    use _container_file_citation <- decode.field("type", decode.string)
    use container_id <- decode.field("container_id", decode.string)
    use end_index <- decode.field("end_index", decode.int)
    use file_id <- decode.field("file_id", decode.string)
    use filename <- decode.field("filename", decode.string)
    use start_index <- decode.field("start_index", decode.int)
    decode.success(ContainerFileCitation(
      container_id:,
      end_index:,
      file_id:,
      filename:,
      start_index:,
    ))
  }

  use type_ <- decode.field("type", decode.string)
  case type_ {
    "file_citation" -> file_citation_decoder()
    "url_citation" -> url_citation_decoder()
    "container_file_citation" -> container_file_citation_decoder()
    "file_path" -> file_path_decoder()
    _ -> {
      echo "annotation_decoder"
      panic
    }
  }
}

pub type Reasoning {
  Reasoning(
    /// Constrains effort on reasoning for reasoning models. Currently supported values are minimal, low, medium,
    /// and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.
    effort: Option(String),
    /// A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's
    /// reasoning process. One of auto, concise, or detailed.
    summary: Option(String),
  )
}

fn reasoning_decoder() {
  use effort <- decode.field("effort", decode.optional(decode.string))
  use summary <- decode.field("summary", decode.optional(decode.string))
  decode.success(Reasoning(effort:, summary:))
}

pub type Text {
  Text(format: Format, verbosity: String)
}

fn text_decoder() {
  use format <- decode.field("format", format_decoder())
  use verbosity <- decode.field("verbosity", decode.string)
  decode.success(Text(format:, verbosity:))
}

pub type Format {
  Format(type_: String)
}

fn format_decoder() {
  use type_ <- decode.field("type", decode.string)
  decode.success(Format(type_:))
}

pub type Tool {
  /// Defines a function in your own code the model can choose to call. Learn
  /// more about [function calling](https://platform.openai.com/docs/guides/
  /// function-calling).
  Function(
    /// The function's name (e.g. get_weather)
    name: String,
    /// Details on when and how to use the function
    description: String,
    /// JSON schema defining the function's input arguments
    parameters: dynamic.Dynamic,
    /// Whether to enforce strict mode for the function call
    strict: Bool,
  )
  /// A tool that searches for relevant content from uploaded files. Learn more
  /// about the [file search tool](https://platform.openai.com/docs/guides/
  /// tools-file-search).
  FileSearch(
    /// The IDs of the vector stores to search.
    vector_store_ids: List(String),
    /// A filter to apply based on file attributes.
    filters: FileSearchFilters,
    /// The maximum number of results to return. This number should be between 1 and 50 inclusive.
    max_num_results: Int,
    /// Ranking options for search.
    ranking_options: RankingOptions,
  )
  ComputerUse(
    /// The height of the computer display.
    display_height: Int,
    /// The width of the computer display.
    display_width: Int,
    /// The type of computer environment to control.
    environment: String,
  )
  WebSearch(
    /// High level guidance for the amount of context window space to use for the search.
    search_context_size: Option(String),
    /// Approximate location parameters for the search.
    user_location: Option(UserLocation),
    /// Filters for the search.
    filters: Option(Filters),
  )
  Mcp(
    allowed_tools: Option(List(String)),
    // TODO parse headers?
    // headers: Option(List(#(String, String))),
    require_approval: ToolMcpRequireApproval,
    server_description: Option(String),
    server_url: String,
    server_label: String,
  )
  // TODO Document these args
  // type: "shell"
  Shell
}

fn tool_decoder() -> Decoder(Tool) {
  decode.one_of(function_decoder(), or: [
    file_search_decoder(),
    computer_use_decoder(),
    web_search_decoder(),
    mcp_decoder(),
    shell_decoder(),
  ])
}

fn web_search_decoder() -> Decoder(Tool) {
  use search_context_size <- decode.field(
    "search_context_size",
    decode.optional(decode.string),
  )
  use filters <- decode.field("filters", decode.optional(filters_decoder()))
  use user_location <- decode.field(
    "user_location",
    decode.optional(user_location_decoder()),
  )
  decode.success(WebSearch(search_context_size:, filters:, user_location:))
}

fn mcp_decoder() -> Decoder(Tool) {
  let require_approval_decoder = fn() {
    let always_decoder = fn() {
      use read_only <- decode.field("read_only", decode.optional(decode.bool))
      use tool_names <- decode.field("tool_names", decode.list(decode.string))
      decode.success(Always(read_only:, tool_names:))
    }
    let never_decoder = fn() {
      use read_only <- decode.field("read_only", decode.optional(decode.bool))
      use tool_names <- decode.field("tool_names", decode.list(decode.string))
      decode.success(Never(read_only:, tool_names:))
    }
    use always <- decode.field("always", decode.optional(always_decoder()))
    use never <- decode.field("never", decode.optional(never_decoder()))
    decode.success(ToolMcpRequireApproval(always:, never:))
  }
  use allowed_tools <- decode.field(
    "allowed_tools",
    decode.optional(decode.list(decode.string)),
  )

  use require_approval <- decode.field(
    "require_approval",
    require_approval_decoder(),
  )
  use server_description <- decode.field(
    "server_description",
    decode.optional(decode.string),
  )
  use server_url <- decode.field("server_url", decode.string)
  use server_label <- decode.field("server_label", decode.string)
  decode.success(Mcp(
    allowed_tools:,
    require_approval:,
    server_description:,
    server_url:,
    server_label:,
  ))
}

fn shell_decoder() -> Decoder(Tool) {
  use _type <- decode.field("type", decode.string)
  decode.success(Shell)
}

fn function_decoder() -> Decoder(Tool) {
  use name <- decode.field("name", decode.string)
  use description <- decode.field("description", decode.string)
  use strict <- decode.field("strict", decode.bool)
  use parameters <- decode.field("parameters", decode.dynamic)
  decode.success(Function(name:, description:, parameters:, strict:))
}

fn computer_use_decoder() -> Decoder(Tool) {
  use display_height <- decode.field("display_height", decode.int)
  use display_width <- decode.field("display_width", decode.int)
  use environment <- decode.field("environment", decode.string)
  decode.success(ComputerUse(display_height:, display_width:, environment:))
}

fn file_search_decoder() -> Decoder(Tool) {
  use vector_store_ids <- decode.field(
    "vector_store_ids",
    decode.list(decode.string),
  )
  use filters <- decode.field("filters", file_search_filters_decoder())
  use max_num_results <- decode.field("max_num_results", decode.int)
  use ranking_options <- decode.field(
    "ranking_options",
    ranking_options_decoder(),
  )
  decode.success(FileSearch(
    vector_store_ids:,
    filters:,
    max_num_results:,
    ranking_options:,
  ))
}

pub type ToolMcpRequireApproval {
  ToolMcpRequireApproval(always: Option(Always), never: Option(Never))
}

pub type Always {
  Always(read_only: Option(Bool), tool_names: List(String))
}

pub type Never {
  Never(read_only: Option(Bool), tool_names: List(String))
}

pub type FileSearchFilters {
  ComparisonFilter(
    /// The key to compare against the value.
    key: String,
    /// Specifies the comparison operator: eq, ne, gt, gte, lt, lte, in, nin.
    type_: String,
    /// The value to compare against the attribute key; supports string, number, or boolean types.
    value: Value,
  )
}

fn file_search_filters_decoder() -> Decoder(FileSearchFilters) {
  decode.one_of(comparison_filter_decoder(), [])
}

fn comparison_filter_decoder() -> Decoder(FileSearchFilters) {
  use key <- decode.field("key", decode.string)
  use type_ <- decode.field("type", decode.string)
  use value <- decode.field("value", value_decoder())
  decode.success(ComparisonFilter(key:, type_:, value:))
}

pub type Value {
  ValueString(String)
  ValueFloat(Float)
  ValueBool(Bool)
  ValueArrayString(List(String))
  ValueArrayFloat(List(Float))
  ValueArrayBool(List(Bool))
}

fn value_decoder() -> Decoder(Value) {
  let value_string_decoder = fn() {
    use value_string <- decode.field("value", decode.string)
    decode.success(ValueString(value_string))
  }
  let value_float_decoder = fn() {
    use value_float <- decode.field("value", decode.float)
    decode.success(ValueFloat(value_float))
  }
  let value_bool_decoder = fn() {
    use value_bool <- decode.field("value", decode.bool)
    decode.success(ValueBool(value_bool))
  }
  let value_array_string_decoder = fn() {
    use value_array <- decode.field("value", decode.list(decode.string))
    decode.success(ValueArrayString(value_array))
  }
  let value_array_float_decoder = fn() {
    use value_array_float <- decode.field("value", decode.list(decode.float))
    decode.success(ValueArrayFloat(value_array_float))
  }
  let value_array_bool_decoder = fn() {
    use value_array_bool <- decode.field("value", decode.list(decode.bool))
    decode.success(ValueArrayBool(value_array_bool))
  }

  decode.one_of(value_string_decoder(), [
    value_float_decoder(),
    value_bool_decoder(),
    value_array_string_decoder(),
    value_array_float_decoder(),
    value_array_bool_decoder(),
  ])
}

pub type RankingOptions {
  RankingOptions(ranker: String, score_threshold: Float)
}

fn ranking_options_decoder() -> Decoder(RankingOptions) {
  use ranker <- decode.field("ranker", decode.string)
  use score_threshold <- decode.field("score_threshold", decode.float)
  decode.success(RankingOptions(ranker:, score_threshold:))
}

pub type Filters {
  Filters(allowed_domains: Option(List(String)))
}

fn filters_decoder() -> Decoder(Filters) {
  use allowed_domains <- decode.field(
    "allowed_domains",
    decode.optional(decode.list(decode.string)),
  )
  decode.success(Filters(allowed_domains:))
}

// fn filters_decoder() -> Decoder(Filters) {
//   use allowed_domains <- decode.field(
//     "allowed_domains",
//     decode.optional(decode.list(decode.string)),
//   )
//   decode.success(Filters(allowed_domains:))
// }

pub type UserLocation {
  UserLocation(
    /// Free text input for the city of the user, e.g. San Francisco.
    city: Option(String),
    /// The two-letter ISO country code of the user, e.g. US.
    country: Option(String),
    /// Free text input for the region of the user, e.g. California.
    region: Option(String),
    /// The IANA timezone of the user, e.g. America/Los_Angeles.
    timezone: Option(String),
    /// The type of location approximation. Always approximate.
    type_: Option(String),
  )
}

fn user_location_decoder() -> Decoder(UserLocation) {
  use city <- decode.field("city", decode.optional(decode.string))
  use country <- decode.field("country", decode.optional(decode.string))
  use region <- decode.field("region", decode.optional(decode.string))
  use timezone <- decode.field("timezone", decode.optional(decode.string))
  use type_ <- decode.field("type", decode.optional(decode.string))
  decode.success(UserLocation(city:, country:, region:, timezone:, type_:))
}

pub type Usage {
  Usage(
    input_tokens: Int,
    input_tokens_details: InputTokensDetails,
    output_tokens: Int,
    output_tokens_details: OutputTokensDetails,
    total_tokens: Int,
  )
}

fn usage_decoder() -> Decoder(Usage) {
  let input_tokens_details_decoder = fn() {
    use cached_tokens <- decode.field("cached_tokens", decode.int)
    decode.success(InputTokensDetails(cached_tokens:))
  }
  let output_tokens_details_decoder = fn() {
    use reasoning_tokens <- decode.field("reasoning_tokens", decode.int)
    decode.success(OutputTokensDetails(reasoning_tokens:))
  }
  use input_tokens <- decode.field("input_tokens", decode.int)
  use input_tokens_details <- decode.field(
    "input_tokens_details",
    input_tokens_details_decoder(),
  )
  use output_tokens <- decode.field("output_tokens", decode.int)
  use output_tokens_details <- decode.field(
    "output_tokens_details",
    output_tokens_details_decoder(),
  )
  use total_tokens <- decode.field("total_tokens", decode.int)
  decode.success(Usage(
    input_tokens:,
    input_tokens_details:,
    output_tokens:,
    output_tokens_details:,
    total_tokens:,
  ))
}

pub type InputTokensDetails {
  InputTokensDetails(cached_tokens: Int)
}

pub type OutputTokensDetails {
  OutputTokensDetails(reasoning_tokens: Int)
}
